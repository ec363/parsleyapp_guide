[["index.html", "The Parsley App Guide About What is a data parser? How does it work? Who is it for? Which plate readers does it work with? Contact", " The Parsley App Guide Eszter Csibra 2024-08-12 About Parsley is a universal plate reader data parsing application. Multiwell plate readers are an important tool in the life sciences. They are frequently used to measure fluorescence, absorbance and luminescence, among other measurement types. As they are heavily used for high-throughput assays and screens, their analysis benefits from automated (programmatic) data analysis. However, most plate readers export raw data in formats that software packages cannot work with, and that do not contain the necessary metadata for downstream analysis. A necessary initial step in every analysis is therefore extracting the data, reformatting it into the correct ‘tidy’ data structure, and joining it with any required metadata: we call this process ‘parsing’. While a few parser functions for certain export formats from certain plate readers have been written, there is no generic tool that can handle data parsing from any plate reader: this is why Parsley was built. Author: Eszter Csibra Version: 1.0.1 Release: Oct 2023 What is a data parser? Imagine a fluorescence intensity measurement on a dilution series of fluorescein gave you the following raw data and you wanted to analyse the data using an existing software package: In its current form, you will get errors with any software, because the data does not look like any recognisable data table object: its rows and columns have irregular meanings, some metadata is included but not helpfully positioned, and most metadata you require for your analysis is missing (eg. fluorophore, buffer, dilution, volume, etc). A parser extracts the data values from the raw data file, along with crucial metadata such as wells (ie. A1-H12), readings (eg. OD600, GFP..), and if applicable, wavelengths (eg. 485nm, for spectrum data) or time points (eg. 30min, for kinetic / timecourse data) into what we call Cropped Data: ..and adds relevant metadata crucial to the downstream analysis to give you Parsed Data: Crucially, during metadata joining, the data is transformed into what is known as ‘tidy data’ format. Tidy data is of the form where every column is a variable, every row is an observation, and every cell contains a single value. In the above example, ‘wells’ is a variable, but ‘A1’ and ‘A2’ (etc) are not variables, they are instances of the ‘wells’ variable, so the Cropped Data is transformed such that the column names are no longer wells, but different fluorescence readings. This table is saved as a CSV file, which can then be used easily for downstream data analysis without requiring manual editing or tidying. How does it work? Standard parser functions built for specific output formats work programmatically, for example they might identify the first line of data by finding the line that begins at the ‘0’ timepoint, or under the first heading starting ‘Measurement’. However, these rules are too specific to be used for a universal parser. Parsley was developed to be as universally applicable as possible, so it makes very few assumptions about the type, orientation and size of the data. It therefore requires user-provided inputs to specify all of these parameters in turn: the type and orientation of the data, the location of data within the export file, as well as some crucial metadata (the names of readings, the order of the wells, and if applicable, the wavelengths used for spectra or the timepoints used for a timecourse). This is why it asks so many questions and is so particular about the exact response it requires! Once data extraction is complete, it labels the data with the most crucial metadata: in other words, it adds the reading names as column names, and adds a column for the wells. For timecourse data, it also adds an extra column for time. To finish, this tidy dataset is joined to user-provided metadata. The completed parsed data is then available to download as a CSV file for downstream analysis. Who is it for? The principal intended user is anyone who wishes to extract and reformat data for downstream analysis but does not wish to code their own parser function. It is expected that in most cases the downstream analysis will be carried out in R, Python or similar, however parsed data can also be useful for downstream analysis in Excel. This tool is not just for those who don’t code. We have found Parsley useful when working with data from new plate readers or new data types, as it provides rapid access to tidy data without the upstream work required to write a bespoke function. It even has applications in data storage and reuse. Tidy data joined to relevant metadata is an excellent way to store research data for personal use, sharing with collaborators, or in preparation for a manuscript submission. (Metadata has an unfortunate habit of getting lost unless we bind it to data!) Which plate readers does it work with? Parsley has been verified to work with the following data formats exported from the following plate readers: Tecan Spark plate reader (SparkControl Magellan software) Standard - direction horizontal/vertical, well data in rows/columns/matrixseparated/matrixXfluor Spectrum - direction horizontal/vertical, well data in rows/columns/matrixseparated/matrixXfluor/matrixnested Timecourse - direction horizontal/vertical, well data in rows/columns BMG LabTech Clariostar Plus plate reader (MARS software) Standard - default export format, -/+unused wells, -/+metadata, wellformats as A1 or A01, -/+transpose Spectrum - default export format, -/+unused wells, -/+metadata, wellformats as A1 or A01, -/+transpose Timecourse - default export format, -/+unused wells, -/+metadata, wellformats as A1 or A01, -/+transpose BioTek Synergy HT plate reader (Gen5 software) Standard - (column format) Timecourse - (row format) BioTek Synergy Neo2 plate reader (Gen5 software) Timecourse - (row format) Molecular Devices SpectraMax iD5 plate reader Standard - (matrix format) Beckman Coulter BioLector Microbioreactor Timecourse - (column format) Enzyscreen GrowthProfiler plate reader Timecourse - (row format) Growth Curves Bioscreen plate reader Timecourse - (row format) PerkinElmer VICTOR Nivo plate reader Timecourse - (column format) Tecan GENios plate reader Timecourse - (row format) As time goes on, we hope to verify more plate reader outputs with Parsley. Please reach out if you use a different instrument and Parsley does (or does not!) work for your data exports. Contact Questions, suggestions or bug reports? Please contact me. "],["guide.html", "Guide A Step by Step Guide to Using Parsley Standard Data Spectrum data Timecourse data Saving and Reusing Parser Functions", " Guide A Step by Step Guide to Using Parsley Welcome to Parsley! We assume you are here because you have exported some data from a plate reader, and you are interested in extracting the data and converting it into a format suitable for downstream analysis. This Guide will take you through the steps of using Parsley to solve this problem. See the About tab for more on what a parser does and why you would use it. See the Help tab if you’re looking for troubleshooting tips or help on how to interpret the error messages. There are three main steps to parsing plate reader data with Parsley using the first ‘Build Your Own Parser’ tab. First, you need to upload your experimental Raw Data file. Second, you will need to create and upload an accompanying Metadata file that contains all the extra information you will need to attach to your data for your downstream analysis. Third, you need to proceed through a guided series of Data Specification steps, to tell the app about your data (such as what type of data it is and where the relevant data cells are located within your Raw Data spreadsheet). These three steps will create a ‘parser function’ or ‘parser’ that the app uses to convert the Raw Data and Metadata into Parsed Data. The Parsed Data can then be downloaded as a CSV file. The parser function you have built can also be saved for use on further files of the same type, using the second ‘Use Saved Parser’ tab. Navigate to the ‘Build Your Own Parser’ tab (left hand link in the top navigation bar) to get started. Standard Data Example data: To illustrate how Parsley works for the purposes of this guide, we will use a simplified version of the first example dataset provided with the app (‘Green fluorescence data (rows)’). Here, a dilution series of the green fluorescent small molecule fluorescein (11 dilutions) was prepared in a 96-well plate, with the highest concentration placed on the left (A1), the lowest on the right (A11) and with buffer blanks in column 12 (A12). This plate was measured for fluorescence intensity in the green fluorescence channel (ex. 485/20, em: 535/25), which I have called the ‘GG2’ channel, in a Tecan Spark plate reader. The first reading was at gain 40, and the second at gain 50. The readings were therefore labelled ‘GG2_gain40’ and ‘GG2_gain50’, respectively. The image below shows how such data might look in Excel after export from a plate reader: this is our Raw Data. Raw Data To start, upload your experimental Raw Data file. On the ‘Build Your Own Parser’ tab, you should see the following instructions at the top of the page: Raw Data: Upload a raw data file from your plate reader experiment. We recommend uploading CSV format files where possible. As most plate readers export files in Excel (.xlsx) format, these need to be converted (you can open them in Excel or similar and use ‘Save As..’). While Parsley can handle Excel files, importing data from Excel files can be slow and can cause issues that are solved by using CSV format. To upload a file, select ‘Upload file’, find your Raw Data file, select a ‘File type’ from the dropdown menu, and click ‘Submit’. (Since v0.1.2, it is also possible to upload tab-separated value (tsv) files, as well as CSV files that use semi-colons (;) instead of commas (,) by selecting the appropriate delimeter.) A successful upload will result in the name of your file appearing below the Submit button, and the entire Raw Data file contents appearing at the bottom of the page. Even if the file is very wide or long, you should be able to scroll to view the entire file. When we upload our fluorescein data, we can see that the correct file name appeared under ‘Uploaded file name’ and also that the entirety of the data is visible at the bottom of the page. A few guidance notes will also appear: Note that the Raw Data table has clickable/selectable cells. This is important for some of the later steps. Be careful: clicking on the column names of any of these data tables reorders those columns. As this action cannot be undone and interferes with a number of steps, it is best to re-upload files if you accidentally click on the column names. These notes highlight the fact that the Raw Data file is displayed in an interactive format that enables you to individually select or deselect cells within the data. This will be important later. In addition, the displayed Raw Data table contains interactive column names that, when clicked, sorts those columns by their values. Do not click on these column names! This reordering cannot be undone. Unfortunately, there’s no mechanism within Shiny to remove this particular interactivity, so if the columns get reordered in this way, it is best to Clear and re-Submit the data, or to reload the app and start again. Metadata Once the Raw Data has been uploaded, follow the instructions to upload a Metadata file: Metadata: Upload a metadata file. For tidy format metadata files, include a ‘well’ column in ‘A1-&gt;H12’ format. To skip metadata addition, choose ‘Skip Metadata’. Metadata files are simple files you can create in Excel or a similar application, in which you add any and all variables necessary for your downstream data analysis. If you’re using an existing software package, the software should specify which variables are required in your parsed data. Parsley accepts metadata in 2 formats: tidy format and matrix format. Tidy format is recommended for metadata. Tidy format Metadata: There are few rules for how to create tidy Metadata files, but they are strict: Metadata files should be prepared in a ‘tidy data’ format. This means the data should be arranged in columns, where each column represents a variable and where the variable name for each column is located in the first row of that column. Metadata must contain a column called ‘well’ that contains entries in the format ‘A1’ to ‘H12’ to specify well positions in a 96-well plate. This is because ‘well’ is the column that will be used for joining the data to the metadata: without ‘well’ this joining action will fail. All other columns are optional and will depend on downstream requirements. For example, for plate reader calibration with FPCountR, the metadata requires at a minimum the additional columns: ‘instrument’, ‘channel_name’, ‘calibrant’, ‘replicate’, ‘mw_gmol1’, ‘dilution’ and ‘volume’. Variable names must be unique (no two columns should have the same name), and contain no spaces or symbols (except underscores, which are tolerated). For example, the Metadata for our fluorescein dilution series might look like this (when assembled in Excel): Matrix format Metadata: As of v0.2.0, Parsley also accepts matrix format metadata. To do this, we have adapted functions from another R package, plater, that was written specifically to allow metadata to be assembled ‘intuitively’, as you would when preparing a plate for an experiment. Matrix format metadata requires each variable being arranged in matrix format, ie. arranged like a multiwell plate. For a 96-well plate, this means the first column contains row names A-H, the first row contains column names 1-12. The name of the metadata variable should be provided in the top left corner cell, and the values of this variable arranged in each ‘well’ slot. Consecutive variables should be arranged below the first, with a 1 row gap between each matrix. Variable names must be unique (no two columns should have the same name), and contain no spaces or symbols (except underscores, which are tolerated). Matrix-format metadata for the fluorescein dilution series would be arranged as follows: On saving this as a CSV and uploading it to Parsley, we should notice once again that the upload triggered the display the file name of the uploaded file below the Submit button, and the contents of that file at the bottom of the page. Unlike the Raw Data file, we might also notice that Metadata is not displayed in an interactive format. It is possible to skip this step, and to use Parsley to extract and tidy your data without joining it to metadata. Choose ‘Load example’, and select ‘Skip metadata’ from the dropdown. You should see the Metadata tab confirm that no metadata has been uploaded. Data Specification Once both data and metadata have been uploaded, a green ‘Build Parser’ button appears below the ‘Instructions for Data Specification’ section. Click the button. Further instructions appear: Proceed through the sections in order. Follow the instructions under each step, then click ‘Set’. Check the submitted values and their results with ‘View’ to toggle the ‘Data specifications’ tab (clicking once will take you to the ‘Data specifications’ tab, clicking again will return you to the Raw Data tab). When satisfied, ‘Lock’ the section to mark it as complete, before proceeding to the next step. There are 7 steps in the Data Specification section. Each section must be completed in turn, and each has 3 buttons below it: ‘Set’, ‘View’ and ‘Lock’ (a lock icon). For a given step, once information has been entered, you must click the ‘Set’ button to confirm the entered information. If no error messages are received, this usually means the section has been completed correctly. Having said this, we’d recommend checking each step with ‘View’. Once satisfied, each section must be locked with the ‘Lock’ icon button to enable you to proceed to the next step. Step 1: Data format Step 1 enables the app to get a broad idea of the kind of data you want to parse. Choose data type and format. Data type: There are three data types. Standard: Single measurement for each well, or single measurement for a series of distinct measurement types (eg. OD600 followed by green fluorescence; or A280 followed by A340). Most absorbance or fluorescence measurements are ‘Standard’. If in doubt: if your data is not Spectrum data or Timecourse data, it is Standard data. Spectrum: Absorbance or fluorescence spectrum data, where a large number of measurements are taken for each well between a range of wavelengths. Timecourse: Timecourse/Time series/Kinetic data in which one, or a series of, measurement(s) are taken at regular intervals. Data format: There are three data formats. Data in Rows (Wells in Columns) - Readings from consecutive measurement channels (eg. OD600, green fluorescence, etc) are arranged in rows. The columns represent different wells in the multiwell plate. Data in Columns (Wells in Rows) - Readings from consecutive measurement channels (eg. OD600, green fluorescence, etc) are arranged in columns. The rows represent different wells in the multiwell plate. Data in Matrix format - Data is arranged in one, or a series of, 8-by-12 grids. Select the Data type and Data format appropriate for your data and click Set. In our fluorescein example, we choose Standard for the Data Type and Data in Rows for the Data Format, as the 1st row represents the 1st reading (a green fluorescence intensity reading at gain 40), and the 2nd row represents a 2nd reading (a green fluorescence intensity reading at gain 50). When we click Set, a Data Specifications tab appears behind the Raw Data tab. The View button can be used to toggle between the Raw Data and Data Specifications tabs. Clicking the View button or selecting the Data Specifications tab directly, we can see that the app feeds back to us on our earlier choices. The choices made at each subsequent step, and resultant intermediate data values, will also appear in this tab. Use the View button to toggle back to the Raw Data tab. Click the lock to confirm the values and continue to Step 2. Step 2: Reading names Step 2 allows the app to collect data about the number of readings used in your experiment, and their names. Specify the number and names of all the readings taken. Readings from a plate reader are typically absorbance or fluorescence measurements. Enter the number of readings. Enter the reading names. First, choose how to input them: they can either be selected from values of cells in the Raw Data (‘Select cells with reading names’), or entered manually (‘Enter reading names manually’). Follow the guidance on namings: The reading names are the labels you want to give each reading. These will become column names in the parsed data. As such, it’s important that the names are unique (no duplicates), and that they do not contain spaces or punctuation, although underscores are OK. For our fluorescein data, we select the cells corresponding to the two reading names: ‘GG2_gain40’ and ‘GG2_gain50’ (in the correct order first to last). Click Set and View. For our fluorescein data, we can see that the app has extracted the correct names in the correct order. Click the lock to confirm the values and continue to Step 3. Step 3: Data from first reading Step 3 begins the process of data extraction. To extract the data from your Raw Data file, the app needs to identify the precise location of the data within the file. We start by telling the app where to find the data for the first reading (Step 3) and then move on to enable it to find the ‘total data’ (the data for all the readings and timepoints; Step 4). You should see the following instructions: Select first and last cell from the first reading. If data is in rows, both cells need to be in the same row. If data is in columns, both cells need to be in the same column. For matrix format data, select cells corresponding to wells A1 and H12. In our fluorescein example, we select the first and last cell of the first reading (the green fluorescence reading at gain 40). As the first reading corresponds to the first row of data, we select the cells with the first and last data values in the top row. We do not select the leftmost cell as that is a timepoint. We do not attempt to select multiple rows, as these would correspond to multiple readings. Selections on large data files can be slow. Be patient! For large files (eg. spectra or timecourse data), the delay between a click and a cell turning blue can take a few seconds. Click Set. If you make a mistake at this step, an Error message will show. The most common mistake is selecting &gt;2 wells, which happens if you don’t deselect the cells you selected in Step 2. Click View. In our fluorescein example, we can see that the app has correctly extracted the data for the first fluorescence reading! If this extracted data contained odd elements (empty cells, cells containing non-data elements), now would be the time to go back and correct it. Click the lock to confirm the values and continue to Step 4. Step 4: Total data Step 4 continues the data extraction process started in Step 3. Follow the instructions: Enter the spacing between data in consecutive readings, to allow the app to find and extract the data from all readings. In order to locate the cells containing the data from every single reading, the app uses two pieces of information: the information from Step 3 about the location of the first reading, and information from this Step about how far apart consecutive readings are located from each other. In some plate reader export files, readings are pasted in consecutive rows, but in others there may be gaps between readings. How many rows separate the data in the first and second readings? (Data in consecutive rows = 1; Data with 1 blank row between channels = 2.) For the purposes of this app, we define ‘spacing’ as ‘How many rows separate the data in the first and second readings?’ Where the readings are in consecutive rows, the 2nd reading is located in the row below the 1st reading, ie. in the row ‘1st reading + 1’. This is defined as a spacing of ‘1’. Where there is a gap of one blank row between readings, the 2nd reading would be in the row ‘1st reading + 2’, so spacing is ‘2’, and so on. If data contains only 1 reading, the number below will be ignored. If your data contains only 1 reading, you already have all the data! You can ‘skip’ this section by leaving in the default ‘1’ spacing value and clicking Set and Lock. (In timecourse data, you will need to provide the number of rows that separate the first time point of the first reading with the first time point of the second reading.) In the fluorescein example, we choose ‘1’ as the data for the 2nd reading is in the row directly below the first, so they are consecutive rows. Click Set and a new tab called Cropped Data should appear behind the Raw Data and Data Spectifications tabs. Click View Cropped Data to view the Total Data as it has been ‘cropped’ out from the Raw Data file. In the fluorescein example, we can see that the data extraction is correct and complete. All of the data has been extracted from the Raw Data file, and no empty or non-data cells remain in the Cropped Data. Click the lock to confirm the values and continue to Step 5. Step 5: Well numbering Step 5 adds well numbers to your data to enable you to identify your samples within each reading. Well numbering also enables you to accurately join the Cropped Data with your uploaded Metadata. Follow the instructions: Select well orientation and starting well. Here, the app wants to match each sample to a well ID. For common 96-well plate formats, enter the well orientation and the starting well to enable such matching. Well orientation is required to specify how the wells are ordered in the Raw Data. A Starting well is required as you may have taken data only from a subset of wells, so the first well may not be ‘A1’. Select both from the dropdown menus, and the app will work out the identity of all the wells in your Cropped Data. Meaning of Well orientation options: ‘A1-&gt;A12’ means ‘A1’, ‘A2’, ‘A3’ … ‘A12’, ‘B1’, ‘B2’… ‘A1-&gt;H1’ means ‘A1’, ‘B1’, ‘C1’ … ‘H1’, ‘A2’, ‘B2’… ‘Custom’ means neither of the above (and will request that you select first and last wells of a row/column of cells that contains the well info). Presets correspond to standard 96-well plates and assume no wells are missing. Where a different multiwell plate is used, or if wells are missing, choose ‘Custom’. If there are wells missing from the expected list of wells, eg. if you only measured wells A1, A2, B1 and B2, the standard (A1-&gt;A12) orientation will not assign correct well naming for you as it assumes the presence of wells A3-A12 which you didn’t measure. Select ‘Custom’. The app will ask you to select cells within the Raw Data file that represent the well IDs. In our fluorescein example, we know that the wells were A1 to A12 with no wells missing, so the starting well was ‘A1’ and the orientation was ‘A1-&gt;A12’. Click Set and View. In our fluorescein example, we can see that it correctly worked out the wells used. Click View Cropped Data. In our fluorescein example, we can see that the Cropped Data has now been labelled with the correct reading names and well names. Click the lock to confirm and continue to Step 6. Step 6: Join metadata Step 6 allows you to check your Metadata. Make sure a metadata file in the stated (tidy/matrix) format has been uploaded above (unless you selected to skip the metadata). Tidy format metadata should be displayed in the Metadata tab with the column names in bold. Make sure the ‘well’ column of the file contains entries for each well in the Cropped Data (in exactly the same notation). Matrix format metadata should be displayed in the Metadata tab with non-specific column names (e.g. V1, V2 or ‘…1’, ‘…2’). Each variable should be displayed as an 8-row by 12-column grid (for 96-well plates), or similarly for other plate sizes, with the variable name in the top left corner of the grid, and with consecutive variables entered below one another separated by a single blank row. Click View Metadata to check the Metadata is correct. Further guidance is provided in the Metadata section of this Guide. Metadata can be cleared and re-uploaded if necessary using the section on the top right. In our fluorescein example, we can see that the uploaded Metadata is in the correct format. (Note that the metadata here represents the entire fluorescein dilution (which was conducted in duplicate in rows A and B), even though we only used row A in the examples above for clarity.) Click the lock to confirm the metadata and continue to Step 7. Step 7: Parse data Step 7 completes the data parsing by joining the Cropped Data with the Metadata. Click the Parse Data button. A Parsed Data tab should appear. In our fluorescein example, we can see that it correctly joined the metadata to the data. A ‘Download parsed data’ button should appear. Download the CSV file. Spectrum data Spectrum Data is a special case of Standard Data in which (i) all readings are either absorbance or fluorescence readings, (ii) the readings differ only by the wavelength at which the reading is taken, and (iii) there are typically hundreds of readings per experiment. Most of the steps for parsing Spectrum Data are identical to those for Standard Data and we refer users to the above sections for the basic explanations of all steps. Example data: For this section, we will use the 4th example dataset provided with the app (‘Absorbance spectrum data (cols)’). Here, a dilution series of the green fluorescent small molecule fluorescein (11 dilutions) was prepared in a 96-well plate, with the highest concentration placed on the left (A1), the lowest on the right (A11) and with buffer blanks in column 12 (A12). An absorbance spectrum scan was carried out on this plate in a Tecan Spark plate reader (wavelengths 200-800nm, with an interval of 1nm). Step 2: Reading names The one place where Spectrum Data differs from Standard Data is in Step 2. Instead of asking users to manually select or input hundreds of reading names corresponding to all the wavelengths used in a spectral scan, the app works out these numbers based on a small number of inputs: the minimum and maximum wavelengths used and the interval (ie. what is the difference, in nm, between the first and second wavelengths). As above, these can be checked with the View button. Step 3: Data from first reading As the wavelengths in Spectrum Data are effectively the readings, it is important to remember that the first reading in spectrum data is the lowest measured wavelength. In our fluorescein example, this means that in Step 3, the appropriate choice of cells is the first and last cell from the 200nm wavelength reading. (Note that fact that the orientation of the selections here differs from the one in Standard Data’s Step 2 above not because the data type is Spectrum Data, but because the data here is in column format where each reading is a separate column. In the example Standard Data above, the data is in row format, where each reading is a separate row.) Timecourse data Timecourse Data is similar to Standard Data but somewhat more complicated, as each reading is carried out multiple times. Most of the steps for parsing Timecourse Data are identical to those for Standard Data and we refer users to the above sections for the basic explanations of all steps. Example data: For this section, we will use a simplified version of the 6th example dataset provided with the app (‘Timecourse data (rows)’). In this experiment, an inducer titration of an mCherry expression vector was carried out. We have truncated the data to only include row B, in which three inducer concentrations were tested, each in triplicate (B2-B4, B5-B7, B8-B10) next to a media blank (B11). A timecourse experiment was carried out on this plate in a Tecan Spark plate reader, with three readings (OD600, red fluorescence and blue fluorescence) taken every 30 minutes for a total duration of 16 hours. Step 2b: Timecourse settings Unlike for other data types, the app contains an extra section for Timecourse data that is positioned after Step 2 in which Readings are specified. This step will create a numerical list of timepoints used in your experiment. This can be achieved in one of two ways: by selection of cells specifying each timepoint directly, or by manually specifying a small set of parameters, from which the app calculates the list for you. To specify timepoint parameters for a calculation of timepoints, select ‘Enter timecourse settings’ from the dropdown menu. This step aims to work out the time points in your experiment using a small set of inputs. You are not required to select or list every timepoint by hand, the app will calculate them for you instead. This is partly because there may be many timepoints, and partly because many plate readers export timepoints in a variety of often unhelpful units (eg. seconds for a day-long timecourse), odd formats (mixing numbers and letters in timepoint cells, eg.’10 min’) or with excessive precision (eg. such that the ‘30 minute’ timepoint is listed as having been taken at ‘32 min’ for one reading and ‘34 min’ for the next reading, frustrating downstream analyses). The basic inputs required to calculate timepoints in Parsley include the first time point, the duration of the time course and the interval (the difference between the first and second time points). These should be easy to obtain from metadata recorded by the software or the user during the experiment. For the mCherry timecourse example, we input a 0 min first timepoint, a 960 min (16h x 60 = 960min) duration and a 30 min interval. Parsley will attempt to use this information to work out the timepoints in our experiment. It might do this by starting from 0 and including 0, 30, 60, … 930 and 960 minutes. If it did this, we would run into problems, since the final timepoint in our experiment is actually at 930 minutes! This is because in our instrument, readings are only taken at the beginning of each interval. So a timecourse with parameters - first timepoint 0min / duration 60min /interval 30min - will have only 2 timepoints (at 0 and 30min), in contrast to the 3 you might expect (at 0, 30 and 60 min). Parsley includes a 4th input here to deal with this problem: ‘Number of timepoints expected’. Parsley will work out the expected timepoints using the ‘intuitive’ logic that readings are taken at every possible opportunity between the first timepoint and the timecourse duration, but it will truncate the timepoint list based on the user expectation, if the user expectation is lower than the naive Parsley calculation. It is therefore important to work out the precise number of timepoints in your data independently. An easy way to do this if you didn’t specify it in your method is to select all the timepoints of one of the readings in Excel, and count the number of rows they take up (assuming the data is in row format). For the mCherry timecourse example, we input ‘32’ expected timepoints, as we know the Tecan Spark takes readings at the beginning of each interval, so taking readings at 30min intervals across a 16h experiment will result in 32 intervals, so 32 timepoints. On clicking Set, we are presented with the following Warning: Note that this is just a warning - not an error. It does not prevent you proceeding or require a change in your inputs. Its presence is there to inform you that there was a mismatch between the ‘intuitive’ calculation that the list of timepoints must be ‘0, 30, … 930, 960min’ (ie. that the last timepoint is at 16h), and the expected timepoint number of 32, which suggests that if the first timepoint is 0min, the last must be at 930min, making the timepoint list ‘0, 30, … 930’. In this case, the latter is correct, so we can Dismiss the notification and proceed. Had there not been a ‘Number of timepoints expected’ input, or had we entered ‘33’, Parsley would have concluded that the data contains a final timepoint at 960 minutes. As this reading doesn’t exist in our data, this would have led to an error or crash in the later steps. Click View to double check the timepoints Parsley has calculated are correct. Note that as of v0.2.0, there is no longer an assumption that the units of timecourse will be specified in minutes. The units are not specified by the app, do not need to be specified by the user, and make no difference to the parsing process. To select cells with numerical timepoint information, select ‘Select cells with timepoints’ from the dropdown menu. As for Step 2 (Reading names), select the two cells corresponding to the first and last timepoints in the data (two cells in a row for column data, and two cells in the same column for row data). The app will extract the values of each cell between the first and last cell selected, and turn these into a list of timepoints. While the app doesn’t check for this, as it doesn’t affect parsing, we recommend that this function is only used on cells that contain strictly numerical data (eg. “10”) rather than a mixture of numbers and characters (eg. “10 min”), as this will help in downstream analyses. Step3: Data from first reading For Timecourse Data, Step 3 is similar to Standard Data, with the important note that the cells for selection need to be the first timepoint of the first reading, and that Parsley assumes that consecutive timepoints of the same reading are grouped together in rows/columns without breaks. This allows you to input the location of the first timepoint of the first reading and for Parsley to extrapolate the location of all timepoints from the first reading. For our mCherry example, we select the first and last cells corresponding to the first (0 min) timepoint of the first reading (OD600). On clicking Set and View, we can see that the app has correctly extracted all the data from the first reading (all the OD600 data). Step 4: Total data As Step 4 requests spacing information between consecutive readings, it is important to remember that for timecourse data, the spacing will typically correspond to the number of timepoints. For our mCherry example, there are no gaps between the last row of the OD600 readings and the first row of the red fluorescence readings. However, we don’t input ‘1’ here, we input ‘32’, since 32 rows separate the first timepoint of the first reading and the first timepoint of the second reading. Clicking Set and View Cropped Data, we can see that the table includes a ‘time’ column. Scrolling down to the boundary between two of the readings, we can verify that Parsley calculated the spacing correctly, as there is a clear distinction between values labelled as OD600 readings and those labelled as red fluorescence readings, as expected. Saving and Reusing Parser Functions Saving your parser On completion of a parser function with the ‘Build Your Own Parser’ tab, a ‘Save Parser’ button will be revealed. Clicking it will assemble all the details you have just specified your data and metadata into a function, which can be used immediately to parse further files, or be downloaded for later use. If you intend to use the saved parser in the current app session, there is no need to download it. Simply click on ‘Parse More Data’ which will take you to the second ‘Use Saved Parser’ tab. If you want to use the parser for further files at a later date, download it. This will download a .RDS file. This is an R data file that is essentially a list of the data specifications in a format that Parsley will recognise when it is uploaded later. Using a saved parser Navigate to the ‘Use Saved Parser’ tab. First, load a saved parser. If you have just made one on the first tab, select ‘Use current parser’ and Submit. If you saved one at an earlier date, select ‘Upload saved parser’ and upload the .RDS file you downloaded earlier. Once the parser function has been uploaded, simply load a new Raw Data file and Metadata file as you would in the first tab, and select Run Parser. This should reveal the Parsed Data and the Download CSV button. (The Cropped Data tab can be checked in case the Parsed Data doesn’t look right.) A note on making parser functions that work for multiple files Before saving parser functions for reuse, it’s worth considering how these parsers work. In basic terms, a parser function is a series of instructions for about how to turn a given Raw Data file into the correct format, with some basic metadata (before you even join the extra Metadata file). Data: Parsley extracts the numerical data itself purely with positional information from the file itself. This means that a parser function will only work on subsequent Raw Datafiles that contain data in the exact position as the original Raw Datafile. Basic metadata: The basic metadata that Parsley requires from the Raw Datafile itself includes the reading names, timepoints (if applicable) and well numbering information. As plate readers export Raw Datafiles that may or may not include this information, there are two ways to specify this information in Parsley: data may be selected (grabbed from a specific location in the file) or fixed (manually entered or calculated). If you directed the app to locations in the data to find information (selected data), it will be set up to do the same for further files and will be able to handle differences between data files, so long as the updated information is recorded in the same positions as in the first file. However, if you manually entered or calculated certain information (fixed data), it will be programmed to always use those manually entered or calculated values for all subsequent files. Helpfully, when a parser is uploaded, you can view its details in the Parser Function tab to check that it will work for your data files. Let’s take an example. In the first example parser (Load Example Parser &gt; 1 Green fluorescence data (rows)) that was made with the first example dataset (1 - Green fluorescence data (rows)), reading names were specified by selecting the positions in the Raw Data that contained that information: i.e., from the first 9 rows of the first column of the data. This is indicated in the Parser Function tab, where the Reading name specification is set to selected, and the indices of the Reading Names are specified in a table: Therefore, for each new file that is parsed with this parser, the channel names will be grabbed from the cells at those same positions, making it possible to use on data with alternative channel names. In contrast, the well names were calculated from well orientation and starting well information, ie. the well data is fixed as ‘A1, A2 …. B12’ for all data processed with that parser. This is also indicated on the Parser Function tab, where Well specification is set to fixed, and the Used Wells are indicated in full: So with this parser, it is assumed that all subsequent data files will use the same well numbering. "],["examples-and-demos.html", "Examples and Demos Function Demos with Example Data Standard Data Spectrum Data Timecourse Data", " Examples and Demos Function Demos with Example Data A wide variety of example data is provided with the app to serve as an illustration of all the data types and formats Parsley can handle, as well as to let you test the app’s functionality. This Demos section includes details of the provenance of each of the provided Example data sets and a few Demos that illustrate how to build parsers for each of these. Standard Data Example data A dilution series of the green fluorescent small molecule fluorescein (11 dilutions) was prepared in duplicate in rows A-B of a 96-well plate, with the highest concentration on the left (A1/B1), lowest on the right (A11/B11) and with buffer blanks in column 12 (A12/B12). The other wells of the 96-well plate were left empty. This plate was measured for fluorescence intensity in the green fluorescence channel (ex. 485/20, em: 535/25), which I have called the GG2 channel, in a Tecan Spark plate reader. The first reading was at gain 40, and the second at gain 50. I have called the readings “GG2_gain40” and “GG2_gain50” respectively. Demo Standard Data Demo Spectrum Data Example data A dilution series of the green fluorescent small molecule fluorescein (11 dilutions) was prepared in duplicate in rows A-B of a 96-well plate, with the highest concentration on the left (A1/B1), lowest on the right (A11/B11) and with buffer blanks in column 12 (A12/B12). The other wells of the 96-well plate were left empty. An absorbance spectrum scan was carried out on this plate in a Tecan Spark plate reader (wavelengths 200-800nm, with an interval of 1nm). Demo Spectrum Data Demo Timecourse Data Example data In this experiment, E. coli cells containing one of two fluorescent protein expression vectors (mCherry or mTagBFP2) were subjected to a titration of their transcriptional inducer (arabinose). The test plate also contained control strains containing an empty plasmid vector, and media blanks. A timecourse experiment was carried out on this plate in a Tecan Spark plate reader, with three readings (OD600, red fluorescence and blue fluorescence) taken every 30 minutes for a total duration of 16 hours. Demo Timecourse Data Demo "],["help.html", "Help Help Page Definitions Troubleshooting", " Help Help Page This Help page includes Troubleshooting tips to solve common problems as well as more details about the Error messages you might come across while using Parsley. If this page doesn’t solve your problem, consult the Guide tab, which contains a step by step walk through of how to use Parsley. Definitions Reading Throughout Parsley, we use the term ‘Reading’ to refer to a type of measurement that is taken for an entire plate. Note, however that we are not referring to a reading of one well, but a reading of every well of an entire plate. For instance, you might run a timecourse assay using a plate reader in which you take a ‘green’ fluorescence intensity measurement (to detect GFP), a ‘red’ fluorescence measurement (to detect RFP) and an absorbance measurement at 600nm, of your entire 96-well plate at regular intervals. We might refer to these then as the first, second and third Readings, respectively. The names you give these Readings might then relate to the target molecule, eg. ‘GFP, RFP, cells’, or they might refer to the filter sets used, eg. ‘green, red, OD600’ or ‘GG2, RR1, OD600’. Most of the time, you will only take one Reading with any one filter set, which means you can call a Reading by the name of that filter set. Calibrations with the FPCountR framework are an exception to this, as they require several Readings in the same filter set across a range of gains. In this case, you will need the names for each distinct Reading to differ so you can distinguish them: you can’t call them ‘GG2, GG2, GG2..’, but you might consider ‘GG2_gain40, GG2_gain50, GG2_gain60’ etc. For a given Reading, there should only be 1 value for any given well at any given timepoint. For a given well, Standard Mode data only has 1 value for any given Reading. (For Standard Mode data with 12 wells and 1 Reading (OD600), the app will expect 12 data points.) For a given well, Timecourse data only has 1 value for any given Reading and time point. (For Timecourse Mode data with 12 wells, 1 Reading (OD600), and 10 time points, the app will expect 120 data points.) It is assumed that all Spectrum data only consists of one spectrum, and that no plate reader would permit export of spectrum data next to non-spectrum data in the same file. But wavelengths in Spectrum data are treated as separate Readings (because Spectrum data is effectively a series of absorbance readings at a range of wavelengths). So for a given well, Spectrum data only has 1 value for any given wavelength (aka Reading). (For Spectrum Mode data with 12 wells and 800 wavelengths (= Readings), the app will expect 9600 data points.) Troubleshooting Data files are not uploading Check if an ‘Uploaded file name’ box has appeared beneath the Submit button. If it did not, you did not select a file with Browse. If a file name appears, check it is the right file. Wait a few seconds, as large files can take a few seconds to load, and large Excel files can be especially slow. We recommend saving Excel format files as CSV files before upload, particularly if you encounter unexpected issues. Allowed file formats are .csv, .tsv, .txt, .xlsx, or .xls. Make sure you have selected an appropriate file and selected the correct file type for the selected file. If you are using CSV format files, and still see no Raw Data, the most common problem is that your CSV file may not end with a new empty line. Open the file in a text editor, put your cursor to the right end of the last line and hit Return. Save the file and try again. How do I create a metadata file? Create a new spreadsheet with Excel or similar. Create a column called ‘well’ (copy/paste this exactly, similar column names will cause an error). Fill this column with ‘A1’ to ‘H12’, or as many of these as you need. Add as many other columns as you need to describe the contents of each well. Save the file as a CSV. Data has been reordered due to clicking on column names in Raw Data tab This cannot be undone, unfortunately. Reload the page and start again. Error messages: Data upload errors Error: File extension needs to be one of the following: ‘csv’, ‘tsv’, ‘txt’, ‘xls’, ‘xlsx’. The selected file does not have an extension corresponding to the appropriate file types. Select another file or save the file in an appropriate format. Error: Ensure that the specified file type matches uploaded file’s extension. The selected file has an extension that doesn’t match the file type selected from the ‘File type’ menu: perhaps you selected a ‘.xlsx’ file but the File type menu is set to ‘CSV’? Error messages: Generic errors Error: Section marked complete. The section whose values you are trying to change are marked complete. To undo this and update the section, unclick the lock icon. Error: Section X/Previous sections marked incomplete. There is an order to the Data Specifications that needs to be followed. Check that Section X has been completed (with ‘View’ or ‘Data Specifications’ tab). If it has, click the Lock icon next to the Section X ‘Set’ button to mark it as complete before moving on to the next section. Error: Select values/cells first. Use the mouse to select cells in the Raw Data table to complete this section, before clicking ‘Set’. Error messages for Step 1: Data format Error: Spectrum data must be provided in row or column format. Parsley cannot handle spectrum data in matrix format. Error: Timecourse data must be provided in row or column format. Parsley cannot handle timecourse data in matrix format. Error messages for Step 2: Reading names Error: Select reading names input method. Select an option under the ‘Reading names specification’ dropdown. Error: Number of reading names does not match number of readings specified. If you have stated there are X readings, you must either a) select X cells to correspond to the readings names (if you selected ‘Select cells with reading names’) or b) input X reading names (if you selected ‘Enter reading names manually’). Error: Reading name selection cannot contain empty cells. Selected cell contents will become column names. Column names cannot be blank! Error: Reading names must be unique. Selected cells or manually entered reading names contain duplicates, which isn’t tolerated. Please specify a list of unique reading names. Error messages for Step 2b: Timecourse settings Error: Select two cells. Error: Select only 1 row/column. Error: Timepoint selection cannot contain empty cells. Check you have selected the correct cells. The selection needs to be exactly two cells - in the same row for column format data, or in the same column for row format data - and none of the cells between the two selected ones can be empty. If you are certain the selected cells are correct, check if you don’t still have cells selected from Step 2. These need to be unselected. They can be easy to forget about or miss, particularly with large file uploads. Error messages for Step 3: Data from first reading Error: Select two cells. Error: Select only 1 row/column. Error: Select an 8 by 12 matrix. Check you have selected the correct cells. For matrix data, Parsley looks for an 8 row by 12 column matrix and flags an error when you select cells with different spacing. If you are certain the selected cells are correct, check if you don’t still have cells selected from Step 2. These need to be unselected. They can be easy to forget about or miss, particularly with large file uploads. Error messages for Step 4: Total data Error: Add first reading data to Section 3 first. Section 3 has been marked complete (Lock icon) without being completed. Error: Reading number must be an integer of 1 or more. Though the numeric input box accepts fractions, the app does not. Error: Do not request data from outside range of file. You have requested row or column numbers that do not exist in your data. The details within the error message should help fix the problem. Probably the number entered for the spacing between readings is too high. Error messages for Step 5: Well numbering Error: Matrix format requires Starting Well = ‘A1’. Matrix format assumes all wells are represented from ‘A1’ to ‘H12’. Error: Select two cells. Error: Select only 1 row/column. Error: Number of selected wells does not match the number of columns/rows of selected data. Custom well numbering: This works like the ‘Data from first reading’ section. Check cell selections from earlier steps have been unclicked. If the data is in ‘rows’, Parsley expected the well names to be arranged in a row and the number of columns to match that of the data. If the data is in ‘columns’, Parsley expected the well names to be arranged in a column and the number of rows to match that of the data. Error: Well name selection cannot contain empty cells. Custom well numbering: every sample must have a non-empty ‘well’ value or data will be lost during parsing. Error messages for Step 7: Parse data Error: Can’t merge Data and tidy Metadata if Metadata does not contain a ‘well’ column. Verify that the Metadata is in tidy format. If so, add a ‘well’ column. If it is in matrix format, select ‘Matrix format’ in the Metadata upload section above, click Submit to reupload the Metadata, before retrying the Parsing. Check that the metadata file was uploaded correctly. If you uploaded Tidy format Metadata, it needs to contain a column labelled ‘well’. Check that Parsley has correctly interpreted that ‘well’ is the column name: column names will appear in bold at the top. If it is displayed further down, edit the CSV file so that the column names are the first line of the spreadsheet. If you uploaded Matrix format Metadata, this error has come up because you selected ‘Tidy format’ under the Metadata format menu. Select ‘Matrix format’ instead, press Submit to re-upload the Metadata correctly, and retry the Parse step. Error messages: Use Saved Parser Tab Error: Parser missing. Upload a saved parser or build one before proceeding. The parser you are trying to load is missing. A common cause of this error is selecting ‘Use current parser’ when one hasn’t yet been completed in the Build Your Own Parser tab. Did you mean to upload a saved .RDS file? Choose ‘Upload saved parser’. Error: Parser incomplete. If the parser was not created with a recent version of Parsley, remake the parser. Parsley has detected a faulty parser function. This may be because the parser was built with an out of date version of Parsley. Remake the parser to fix this issue. Error: Parser file could not be uploaded. Check that it is a .RDS file created with Parsley. Error: The file extension for a parser need to be ‘RDS’. An error occurred while reading an uploaded file. The file may not be in the correct .RDS format. Are you sure you are uploading a parser function file made by Parsley? Error: Upload a raw data file Error: Upload a metadata file Parsing cannot proceed without a raw data file and metadata file. Warning messages for Step 2b: Timecourse settings Warnings are not errors. They do not prevent you proceeding or require you to change your inputs. Warning: Fewer expected timepoints than calculated timepoints. Warning: More expected timepoints than calculated timepoints. This is a notification that Parsley has identified a mismatch between (i) the ‘intuitive’ calculation that the list of timepoints must start from the ‘first timepoint’ and carry on every interval until the ‘duration’ timepoint, and (ii) the list of timepoints calculated from the ‘first timepoint’ and the ‘expected timepoint number’. For example, if the inputs had been: {first timepoint: 0, interval: 30, duration: 960, expected timepoint number: 32}, then the ‘intuitive’ calculation gives the list: {0, 30, … 960}, whereas the ‘expected’ calculation gives: {0, 30, … 930}. In case of a mismatch, Parsley chooses the shorter of the two lists, and presents a warning confirming the final list. You can then verify if this is the correct list. If it is, you can proceed. If it isn’t, you can correct the inputs. More details about these calculations are given in the Guide section. "],["news.html", "News Releases Version 1.0.1 Version 1.0.0 Version 0.2.0 Version 0.1.3 Version 0.1.2 Version 0.1.1 Version 0.1.0", " News Releases Version 1.0.1 Release: Oct 2023 Bug fixes. Added error handling to catch issues in step 2 (reading names specification), that previously caused the app to crash during step 5 (well numbering). Documentation updates. Help tab: Updated error messages. Version 1.0.0 Release: Oct 2023 Major improvements to functionality. Added ability to download built parsers, and upload them for quick parsing of similar plate reader files. Parsing new data files now only requires (i) uploading a saved parser function, along with new raw data and metadata, and (ii) clicking a ‘Run Parser’ button. Example parsers are also provided for all example data types. Major UI updates. Added section for saving and downloading parser at the bottom of the Build Your Own Parser tab. Added Use Saved Parser tab for handling uploaded parsers. This tab is laid out similarly to the first tab, with the addition of a Parser Function tab that includes a complete description of the loaded parser function. Documentation updates. Updated Guide and Help pages about new functionality. Version 0.2.0 Release: Oct 2023 Improvements to functionality. Added ability to upload files in Excel format. Removed requirement for units to be in minutes. Added ability to grab timepoints by selecting these directly from the data. Added ability to upload metadata files in matrix format (including a new example file). Bug fixes Added error handling to catch issues with the data/metadata upload step that previously caused the app to crash. Minor UI updates. Added row numbers to most tables. Updates to the documentation. Updated Guide and Help pages about new functionality. Version 0.1.3 Release: Jun 2023 Minor improvements to functionality. Updated file handling checks to restrict uploaded files to compatible file types. Minor wording corrections in the documentation. Version 0.1.2 Release: May 2023 Minor improvements to functionality. Added ability to skip addition of metadata to allow data extraction + tidying without metadata joining. Expanded data import from comma-separated value (CSV) format only to data that is delimited by semi-colons or tabs (tab-separated data, or .tsv). Removed requirement for ‘custom’ well list to include a well in ‘A1’/‘H12’ format. Minor wording changes in BYOP tab. Minor documentation updates. About tab: Instrument compatibility section expanded. Guide tab: Updated guide to incorporate recent changes. Help tab: Updated error messages. Version 0.1.1 Release: May 2023 No changes in app functionality. Minor UI and wording changes to the app. Minor changes to Example Data, which have been simplified. Major documentation updates. Guide refined and updated. Diagrams added. Sections on Spectrum and Timecourse added. Notation changed from ‘Channel’ to ‘Reading’. Help page: Updated Definitions. About tab: Instrument compatibility section added. Demos tab added, with example data details and demo screen recordings. News tab added. Version 0.1.0 Release: April 2023 Initial release of Parsley. "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
